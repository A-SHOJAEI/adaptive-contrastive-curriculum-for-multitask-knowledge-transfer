experiment_name: adaptive_contrastive_mmlu
seed: 42
model:
  base_model: bert-base-uncased
  hidden_dim: 768
  projection_dim: 256
  num_tasks: 57
  dropout: 0.1
  freeze_base: false
data:
  dataset_name: cais/mmlu
  subset: all
  max_samples_per_task: 500
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  max_seq_length: 512
  num_workers: 0
curriculum:
  enabled: true
  warmup_epochs: 2
  strategy: uncertainty_gradient
  temperature: 2.0
  update_frequency: 100
  min_task_weight: 0.1
  max_task_weight: 3.0
contrastive:
  enabled: true
  temperature: 0.07
  lambda_contrastive: 0.3
  lambda_classification: 0.7
  negative_samples: 4
  inter_task_contrast: true
training:
  num_epochs: 10
  batch_size: 16
  gradient_accumulation_steps: 2
  learning_rate: 2.0e-05
  weight_decay: 0.01
  warmup_ratio: 0.1
  max_grad_norm: 1.0
  mixed_precision: true
  scheduler:
    type: cosine
    num_cycles: 0.5
  early_stopping:
    enabled: true
    patience: 3
    min_delta: 0.001
    monitor: val_accuracy
  checkpoint:
    save_best: true
    save_last: true
    monitor: val_accuracy
    mode: max
evaluation:
  batch_size: 32
  metrics:
  - accuracy
  - f1_macro
  - cross_domain_transfer
  - task_confusion
logging:
  log_interval: 50
  use_mlflow: true
  use_tensorboard: true
  save_dir: results
